{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgVYfPuCzwKU"
      },
      "source": [
        "# Prerequisites\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcL936uOzRP9"
      },
      "outputs": [],
      "source": [
        "!unzip pre_saved_assests/mitdb.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsuXPzcRWpwe"
      },
      "source": [
        "Install WFDB to read files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run these two commands in terminal:\n",
        "\n",
        "source venv/bin/activate\n",
        "\n",
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQlrWSuuoY_I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import glob \n",
        "from scipy import signal\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.model_selection import (train_test_split, cross_val_score, KFold)\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from matplotlib import gridspec\n",
        "import keras.backend as K\n",
        "from PIL import Image\n",
        "import gc\n",
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os.path\n",
        "from os import path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HVZLXYCrNYX"
      },
      "source": [
        "# Splitting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJhEIvcVrRI-"
      },
      "source": [
        "Global variables used for splitting functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyUPIpoArHXf"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "abnormal = ['L','R','V','/','A','f','F','j','a','E','J','e','S']\n",
        "normal = ['.','N']\n",
        "af = \"(AFIB\"\n",
        "\n",
        "allowed = ['(AFIB','(N', '']\n",
        "\n",
        "pts = ['100', '101', '102', '103', '104', '105', '106', '107',\n",
        "       '108', '109', '111', '112', '113', '114', '115', '116',\n",
        "       '117', '118', '119', '121', '122', '123', '124', '200',\n",
        "       '201', '202', '203', '205', '207', '208', '209', '210',\n",
        "       '212', '213', '214', '215', '217', '219', '220', '221',\n",
        "       '222', '223', '228', '230', '231', '232', '233', '234']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0txE4X6QoVWW"
      },
      "outputs": [],
      "source": [
        "def test_symbols(data_path):\n",
        "\n",
        "    for file in glob.iglob(f'{data_path}/*.hea'):\n",
        "        thing = file[0:9]\n",
        "        if thing == 'mitdb/201':\n",
        "            record = wfdb.rdrecord(thing)\n",
        "            annotation = wfdb.rdann(thing,'atr')\n",
        "            sym = annotation.symbol\n",
        "            print(len(annotation.aux_note))\n",
        "\n",
        "def load_ecg(file):\n",
        "    '''Reads a signal ECG and gets the physical signal (raw data) and associated annotations and symbols\n",
        "        Parameters\n",
        "        ----------\n",
        "        file : dat file\n",
        "            A dat file containing a raw ECG\n",
        "        Returns\n",
        "        ------\n",
        "        p_signal : list\n",
        "            numerical form of ECG\n",
        "        sym : char\n",
        "            Beat annotation\n",
        "        samp : int\n",
        "            Location of R peak\n",
        "        aux_note : str\n",
        "            Rhythm annotation\n",
        "        \n",
        "        References\n",
        "        ----------\n",
        "        https://towardsdatascience.com/detecting-heart-arrhythmias-with-deep-learning-in-keras-with-dense-cnn-and-lstm-add337d9e41f\n",
        "    '''\n",
        "    record = wfdb.rdrecord(file)\n",
        "    ann = wfdb.rdann(file, 'atr')\n",
        "    p_signal = record.p_signal \n",
        "    aux_note = ann.aux_note\n",
        "    \n",
        "    sym = ann.symbol\n",
        "    samp = ann.sample\n",
        "\n",
        "    return p_signal, sym, samp, aux_note\n",
        "\n",
        "# This makes a dataset given a directory path, the associated frequency and the abnormal classes\n",
        "#it makes 3 datasets \n",
        "# X dataset = signal dataset\n",
        "# Y dataset = binary annotation \n",
        "# sym_all = associated beat symbol \n",
        "\n",
        "\n",
        "def make_dataset(data_path,num_sec, fs, samples=pts, exclude_other=True):\n",
        "    '''Makes a segmented dataset from a set of ECG samples\n",
        "        Parameters\n",
        "        ----------\n",
        "        data_path : str\n",
        "            Path to database\n",
        "\n",
        "        num_sec : int\n",
        "            number of seconds to sample on either side of an R peak\n",
        "\n",
        "        fs : int\n",
        "            sampling frequency. MUST be equal to sampling frequency of databse\n",
        "\n",
        "        samples : list\n",
        "            Set of samples to be included in the dataset\n",
        "\n",
        "        exclude_other : bool\n",
        "            Depricated\n",
        "\n",
        "        Returns\n",
        "        ------\n",
        "        X_all : np.ndarray\n",
        "            A set of segmented ECGs\n",
        "        Y_all : np.ndarray\n",
        "            A set of beat annotations\n",
        "        rhythm_all : np.ndarray\n",
        "            A set of rhythm annotations\n",
        "        \n",
        "        References\n",
        "        ----------\n",
        "        https://towardsdatascience.com/detecting-heart-arrhythmias-with-deep-learning-in-keras-with-dense-cnn-and-lstm-add337d9e41f\n",
        "    '''\n",
        "    num_cols = 2*num_sec * fs\n",
        "    X_all = np.zeros((1,num_cols))\n",
        "    Y_all = np.zeros((1,1))\n",
        "    sym_all = []\n",
        "    rhythm_all = []\n",
        "    max_rows = []\n",
        "    limit = 0\n",
        "    flag = True\n",
        "    \n",
        "    \n",
        "    for patient in samples:\n",
        "\n",
        "        file = data_path + patient \n",
        "        limit = limit+1\n",
        "   \n",
        "        p_signal,sym,samp, aux_note = load_ecg(file)\n",
        "      \n",
        "       # rhythm_all.append(aux_note[0])\n",
        "        \n",
        "\n",
        "        p_signal = p_signal[:,0]\n",
        "        df_ann = pd.DataFrame({'atr_sym':sym, 'atr_sample':samp, 'aux_note':aux_note})\n",
        "       # df_ann = df_ann.loc[df_ann.atr_sym.isin(abnormal + normal)]\n",
        "    \n",
        "        X,Y,sym, rhythm = build_XY(p_signal,df_ann, num_cols, num_sec, fs, exclude_other)\n",
        "        sym_all = sym_all+sym\n",
        "        rhythm[0]=str(aux_note[0])\n",
        "        rhythm_all = rhythm_all+rhythm\n",
        "        max_rows.append(X.shape[0])\n",
        "        X_all = np.append(X_all,X,axis = 0)\n",
        "        Y_all = np.append(Y_all,Y,axis = 0)\n",
        "    \n",
        "\n",
        "\n",
        "    X_all = X_all[1:,:]\n",
        "    Y_all = Y_all[1:,:]\n",
        "\n",
        "\n",
        "\n",
        "    return X_all, convert_to_label(rhythm_all) \n",
        "\n",
        "# this function builds the X,Y matrices for each beat\n",
        "# it also returns the original symbols for Y\n",
        "# Uses a dataframe to keep track of stuff\n",
        "\n",
        "\n",
        "def split_by_patient(train_val_split=None):\n",
        "    '''Takes a set of samples and produces a patient split i.e. No samples from\n",
        "    any one patient can be in both the training and validation set.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        train_val_split : float\n",
        "            % split in the validation set\n",
        "        Returns\n",
        "        ------\n",
        "        pts_train : list\n",
        "            Set of samples to train on\n",
        "        pts_valid : list\n",
        "            Set of samples to validate on\n",
        "        \n",
        "        \n",
        "        References\n",
        "        ----------\n",
        "        https://towardsdatascience.com/detecting-heart-arrhythmias-with-deep-learning-in-keras-with-dense-cnn-and-lstm-add337d9e41f\n",
        "    '''   \n",
        "    pts_train, pts_valid = None, None\n",
        "\n",
        "    if (train_val_split==None):\n",
        "        random.seed( 42 )\n",
        "        pts_train = random.sample(pts, 36)\n",
        "        pts_valid = [pt for pt in pts if pt not in pts_train]\n",
        "    else:\n",
        "      #  seed = 4\n",
        "        seed = None   #Truly random\n",
        "        pts_train, pts_valid = train_test_split(pts, random_state=seed, test_size=train_val_split)\n",
        "\n",
        "   \n",
        "\n",
        "    return pts_train, pts_valid\n",
        " \n",
        "def split_randomly(X_all, Y_all):\n",
        "    '''Takes a set of samples and produces a random split.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_all : np.ndarray\n",
        "        Set of ECGs\n",
        "    Y_all : np.ndarray\n",
        "        Set of ECG labels\n",
        "    Returns\n",
        "    ------\n",
        "    X_train : np.ndarray\n",
        "        ECGs to train on\n",
        "    Y_train : np.ndarray\n",
        "        Lables associated with training set\n",
        "    X_valid : np.ndarray\n",
        "        ECGs to validate on\n",
        "    Y_valid : np.ndarray\n",
        "        ECGs associated with the validation set\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    https://towardsdatascience.com/detecting-heart-arrhythmias-with-deep-learning-in-keras-with-dense-cnn-and-lstm-add337d9e41f\n",
        "    '''\n",
        "\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X_all, Y_all, test_size=0.25, random_state=42)\n",
        "    return X_train, X_valid, y_train, y_valid\n",
        "\n",
        "\n",
        "def build_XY(p_signal, df_ann, num_cols, num_sec, fs, exclude_other):\n",
        "    '''Helper method used to build dataset based on pandas dataframes\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "          p_signal : np.ndarray\n",
        "              An ECG\n",
        "          df_ann : pd.DataFrame\n",
        "              pd.DataFrame({'atr_sym':sym, 'atr_sample':samp, 'aux_note':aux_note}). A dataframe \n",
        "              containing the beat annotation, the location of the R-peak and the rhythm annotation.\n",
        "          num_cols : int\n",
        "              Number of points in an ECG sample\n",
        "          num_sec : Integral type\n",
        "              Required number of seconds to sample on either side of an R-peak\n",
        "          fs : int\n",
        "              Frequency at which the dataset was sampled at\n",
        "          exclude_other : bool\n",
        "              Depricated\n",
        "          Returns\n",
        "          ------\n",
        "          X : np.ndarray\n",
        "              An array containing ECG samples\n",
        "          Y_train : np.ndarray\n",
        "              An array of zeroes and ones relating to wether a beat is abnormal or\n",
        "              not\n",
        "          sym : np.ndarray\n",
        "              An array of beat annotations for each sample\n",
        "          rhythm : np.ndarray\n",
        "              An array of rhythm annotations for each sample\n",
        "          \n",
        "          References\n",
        "          ----------\n",
        "          https://towardsdatascience.com/detecting-heart-arrhythmias-with-deep-learning-in-keras-with-dense-cnn-and-lstm-add337d9e41f\n",
        "    '''  \n",
        "    num_rows = len(df_ann)\n",
        "    X = np.zeros((num_rows, num_cols))\n",
        "    Y = np.zeros((num_rows,1))\n",
        "    rhythm = []\n",
        "    sym = []\n",
        "   \n",
        "    \n",
        "    # keep track of rows\n",
        "    max_row = 0\n",
        "    for atr_sample, atr_sym, aux_note in zip(df_ann.atr_sample.values, df_ann.atr_sym.values, df_ann.aux_note.values):\n",
        "       \n",
        "   \n",
        "        # left = max([0,(atr_sample) ])\n",
        "        # right = min([len(p_signal),(atr_sample + num_sec*2*fs) ])\n",
        "       \n",
        "        left = max([0,(atr_sample - num_sec*fs) ])\n",
        "        right = min([len(p_signal),(atr_sample + num_sec*fs) ])\n",
        "\n",
        "        x = p_signal[left: right]\n",
        "        \n",
        "        if len(x) == num_cols:\n",
        "            X[max_row,:] = x\n",
        "            Y[max_row,:] = int(atr_sym in abnormal)\n",
        "            rhythm.append(aux_note)\n",
        "            sym.append(atr_sym)\n",
        "            max_row += 1\n",
        "    X = X[:max_row,:]\n",
        "    Y = Y[:max_row,:]\n",
        "   \n",
        "    \n",
        "    return X,Y,sym,rhythm\n",
        "\n",
        "# def getAbnormalIndex(atr_sym,atr_sample):\n",
        "#     ab_index = [b for a,b in zip(atr_sym,atr_sample) if a in abnormal][:10]\n",
        "#     return ab_index\n",
        "\n",
        "def convert_to_label(rhythm):\n",
        "    '''Helper method used to determine a sample's rhythm annotation based on\n",
        "    the previous samples. See: https://www.physionet.org/physiotools/wpg/wpg_30.htm for how the\n",
        "    rhythm annotations work in the MIT-BIH arrythmia dataset\n",
        "\n",
        "          Parameters\n",
        "          ----------\n",
        "          rhythm : np.ndarray\n",
        "              A set of rhythm annotations based on the MIT-BIH symbology\n",
        "        \n",
        "    \n",
        "          Returns\n",
        "          ------\n",
        "          R_all : np.ndarray\n",
        "              A set of rhythm annotations encoded with integers.\n",
        "        \n",
        "    '''    \n",
        "    afib_bit = 0\n",
        "    normal_bit = 0\n",
        "    other_bit = 0\n",
        "    count_other = 0\n",
        "    count_afib = 0\n",
        "    count_normal = 0\n",
        "    count_missed = 0\n",
        "  \n",
        "    R_all = []\n",
        "    for i in rhythm:\n",
        "        #print(i)\n",
        "        if '(AFIB' in i:\n",
        "      \n",
        "            afib_bit = 1\n",
        "            normal_bit = 0\n",
        "            other_bit = 0\n",
        "            count_afib = count_afib + 1\n",
        "            \n",
        "        elif '(N' in i:\n",
        "      \n",
        "            afib_bit = 0\n",
        "            normal_bit = 1\n",
        "            other_bit = 0\n",
        "            count_normal = count_normal + 1\n",
        "            \n",
        "        elif '(AFIB' not in i and '(N' not in i and i != '':\n",
        "         \n",
        "            afib_bit = 0\n",
        "            normal_bit = 0 \n",
        "            other_bit = 1\n",
        "            count_other = count_other + 1\n",
        "            \n",
        "\n",
        "        if normal_bit == 1:\n",
        "            R_all.append(0)\n",
        "        elif afib_bit == 1:\n",
        "            R_all.append(1)\n",
        "       \n",
        "        elif other_bit == 1:\n",
        "            R_all.append(2)\n",
        "\n",
        "    return R_all\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2B1D2P5rslP"
      },
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOHn8WEqvjqi"
      },
      "source": [
        "### Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b37hJ1XxWU9j"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import medfilt\n",
        "def median_filt(data):\n",
        "  \"\"\"Applies a median filter to input ECG signal.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "      data : np.ndarray\n",
        "          An array containing an ECG signal\n",
        "  Returns\n",
        "  ------\n",
        "      new_data : np.ndarray\n",
        "          Same input signal with a median filter applied to it.\n",
        "  \"\"\"\n",
        "  new_data = []\n",
        "  for point in data:\n",
        "    point = medfilt(point)\n",
        "    new_data.append(point)\n",
        "  return np.asarray(new_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWiRSyu_WXbo"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import iirnotch,filtfilt\n",
        "def notch_filt(data):\n",
        "  \"\"\"Applies a notch filter to an input ECG signal.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "      data : np.ndarray\n",
        "          An array containing an ECG signal\n",
        "  Returns\n",
        "  ------\n",
        "      new_data : np.ndarray\n",
        "          Same input signal with a notch filter applied to it.\n",
        "  \"\"\"\n",
        "  new_data = []\n",
        "  samp_freq = 360  # Sample frequency\n",
        "  notch_freq = 60.0  # Frequency to be removed from signal\n",
        "  quality_factor = 30.0 # this is incorrectly used as a constant \n",
        "  b_notch, a_notch = iirnotch(notch_freq, quality_factor, samp_freq)\n",
        "  for point in data:\n",
        "    point = filtfilt(b_notch, a_notch, point)\n",
        "    new_data.append(point)\n",
        "  return np.asarray(new_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV5hBr8-v2u1"
      },
      "source": [
        "### Make Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSpVbCm0alq"
      },
      "source": [
        "The cell below accomplishes two things. Firstly, it *should* force images to be 128 by 128. Secondly, it *should* help with matplotlib's issues with memory leakage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c8AS5Rerqqk"
      },
      "outputs": [],
      "source": [
        "#desired pixel size * 0.0139\n",
        "plt.rcParams[\"figure.figsize\"] = [1.78, 1.78]\n",
        "plt.rcParams[\"figure.autolayout\"] = True\n",
        "matplotlib.use('Agg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKxSmE-EvzHE"
      },
      "outputs": [],
      "source": [
        "def ecg_to_greyscale_image(array, labels,split,save = True,incl_other = False):\n",
        "    \"\"\"Function used to make a set of grayscale 2D ECG images from a set of \n",
        "    ECGs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        array : np.ndarray\n",
        "            Array of ECG signals\n",
        "        lables : np.ndarray\n",
        "            Array of lables associated with ECGs\n",
        "        split : str\n",
        "            The name of the split (train/test/validation etc.)\n",
        "        save : bool\n",
        "            Flag used to tell the function wether or not it should save the \n",
        "            images it produces (defaults to True)\n",
        "       \n",
        "    \"\"\"\n",
        "\n",
        "    cN = 0\n",
        "    cA = 0\n",
        "    cO = 0\n",
        "    print(list(set(labels)))\n",
        "    #filename = ''\n",
        "    for count in tqdm(range(len(array))):\n",
        "        \n",
        "        fig = plt.figure()\n",
        "        plt.ioff()\n",
        "        plt.axis(\"off\")\n",
        "        plt.plot(array[count],'k') \n",
        "\n",
        "        if save == True:\n",
        "            if labels[count] == 1:\n",
        "                \n",
        "                filename =  './images_'+split+'/af/af_' + str(cA)+'.png'\n",
        "                cA += 1\n",
        "            elif labels[count] == 0:\n",
        "                filename =  './images_'+split+'/normal/normal_' + str(cN)+'.png'\n",
        "                cN += 1 \n",
        "            else:\n",
        "              if incl_other:\n",
        "                filename =  './images_'+split+'/other/other_' + str(cO)+'.png'\n",
        "                cO += 1\n",
        "            fig.savefig(filename)\n",
        "\n",
        "        fig.clear() \n",
        "        plt.close(fig) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeFmedUIVQ3_"
      },
      "source": [
        "# Usecases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOhRqs8fwBLk"
      },
      "source": [
        "## Make datasets from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmF4PFapwufH"
      },
      "outputs": [],
      "source": [
        "# for creating the necessary directories\n",
        "if path.exists('images_train') == False:\n",
        "  os.mkdir('images_train')\n",
        "  os.mkdir('images_train/af')\n",
        "  os.mkdir('images_train/normal')\n",
        "\n",
        "if path.exists('images_test') == False:\n",
        "  os.mkdir('images_test')\n",
        "  os.mkdir('images_test/af')\n",
        "  os.mkdir('images_test/normal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD8KseC1ra6x"
      },
      "outputs": [],
      "source": [
        "path = 'mitdb/'\n",
        "df = pd.DataFrame()\n",
        "num_sec = 1\n",
        "fs = 360\n",
        "split = 0.1\n",
        "\n",
        "# Get the patient samples to be used in test and training sents\n",
        "train,test = split_by_patient(split)\n",
        "\n",
        "# Creates the dataset\n",
        "X_train, Y_train = make_dataset(path, num_sec, fs,train,True)\n",
        "X_test, Y_test = make_dataset(path, num_sec, fs,test,True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYY74ZxKXKDQ"
      },
      "outputs": [],
      "source": [
        "# Applies median and notch filters to training and test sets\n",
        "\n",
        "X_train = median_filt(X_train)\n",
        "X_train = notch_filt(X_train)\n",
        "\n",
        "X_test= median_filt(X_test)\n",
        "X_test = notch_filt(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('X_train.npy',X_train)\n",
        "np.save('Y_train.npy',Y_train)\n",
        "np.save('X_test.npy',X_test)\n",
        "np.save('Y_test.npy',Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHtV2ORXxJe2"
      },
      "outputs": [],
      "source": [
        "ecg_to_greyscale_image(X_train,Y_train,'train')\n",
        "ecg_to_greyscale_image(X_test,Y_test,'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_NFK6uqrxsT"
      },
      "source": [
        "## Make datasets from presaved splits:\n",
        "i.e. If you choose not to make your own splits you can use the presaved ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wC7OH6prrML",
        "outputId": "d534462e-9fc1-46f2-e37a-7409e23db1c9"
      },
      "outputs": [],
      "source": [
        "!unzip pre_saved_assests/saved_data_splits.npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuNeclJkvMqa"
      },
      "outputs": [],
      "source": [
        "X_train = np.load('X_train.npy')\n",
        "Y_train = np.load('rhythm_train.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "Y_test = np.load('rhythm_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0CctRePvsWP"
      },
      "outputs": [],
      "source": [
        "X_train = median_filt(X_train)\n",
        "X_train = notch_filt(X_train)\n",
        "\n",
        "X_test= median_filt(X_test)\n",
        "X_test = notch_filt(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfijg8XvYBqr"
      },
      "outputs": [],
      "source": [
        "# for creating the necessary directories\n",
        "if path.exists('/content/images_train') == False:\n",
        "  os.mkdir('/content/images_train')\n",
        "  os.mkdir('/content/images_train/af')\n",
        "  os.mkdir('/content/images_train/normal')\n",
        "\n",
        "if path.exists('/content/images_test') == False:\n",
        "  os.mkdir('/content/images_test')\n",
        "  os.mkdir('/content/images_test/af')\n",
        "  os.mkdir('/content/images_test/normal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLs2_2SPX5vr"
      },
      "outputs": [],
      "source": [
        "ecg_to_greyscale_image(X_train,Y_train,'train')\n",
        "ecg_to_greyscale_image(X_test,Y_test,'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r2mV9rTb3PJ"
      },
      "source": [
        "## Moving dataset into presaved assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRODBP0Ib6DW"
      },
      "outputs": [],
      "source": [
        "!zip -r images.zip images_train images_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPh_83Ckb8cd",
        "outputId": "667ce4cd-5f98-4442-dff1-f9e84ce8914e"
      },
      "outputs": [],
      "source": [
        "%cp -av images.zip pre_saved_assests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwspaMg-hSPC"
      },
      "source": [
        "# Next: \n",
        "With your new datasets, you can now move to the generative component: https://colab.research.google.com/drive/1RTMFgeI8X0Kchjicr6fd0OHqGZzmaskL?usp=sharing\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "cc414e0b3354e9e15d1dfba118355067b70b63730e80deb65fb9da2ad81d92c8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
