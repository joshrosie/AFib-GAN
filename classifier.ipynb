{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anbSmotr6Xd_"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTgEn3e_4IIa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from keras import layers\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from matplotlib import gridspec\n",
        "import keras.backend as K\n",
        "from PIL import Image\n",
        "import gc\n",
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, LearningRateScheduler, ReduceLROnPlateau,\n",
        "                                        CSVLogger, EarlyStopping)\n",
        "\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCvAygS6cai5"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H8p9S5C-oy0"
      },
      "outputs": [],
      "source": [
        "def conv_jun():\n",
        "    \"\"\"A classifier based off of the work by Jun et al. (https://arxiv.org/abs/1804.06812).\n",
        "    The original classifier is built for multi-class classification. We make several\n",
        "    adjustments to make it better suited for our purposes. Firstly, we add a Gaussian noise\n",
        "    layer. Secondly, we add dropout after each convolutional block. Finally, we reduce the \n",
        "    number of features in each convolutional layer by a factor of 2.\n",
        "\n",
        "    Returns\n",
        "    ------\n",
        "       model : tf.keras.Model\n",
        "          A model object\n",
        "    \"\"\"\n",
        "    input = layers.Input(shape=(128,128,1))\n",
        "     \n",
        "    noise = layers.GaussianNoise(0.1)(input)\n",
        "    \n",
        "    x = layers.Conv2D(32, 3, 1, padding='same')(noise)\n",
        "    x = layers.ELU()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    dropout = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Conv2D(32, 3, 1, padding='same')(x)\n",
        "    x = layers.ELU()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    dropout = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), strides = 2, padding='same')(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 1, padding='same')(x)\n",
        "    x = layers.ELU()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    dropout = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, 1, padding='same')(x)\n",
        "    x = layers.ELU()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    dropout = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), strides = 2, padding='same')(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3, 1, padding='same')(x)\n",
        "    x = layers.ELU()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    dropout = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3, 1, padding='same')(x)\n",
        "    x = layers.ELU()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    dropout = layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2), strides = 2, padding='same')(x)\n",
        "  \n",
        "    x = layers.Dense(1024)(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    \n",
        "    \n",
        "    dropout = layers.Dropout(0.5)(x)\n",
        "    flatten = layers.Flatten()(dropout)\n",
        "    \n",
        "    dense = layers.Dense(1,activation='sigmoid')(flatten)\n",
        "    model = tf.keras.Model(inputs = input,outputs = dense)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP2Jzwu7rbZl"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "from tensorflow.keras.callbacks import Callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWxn0NVHrX3P"
      },
      "outputs": [],
      "source": [
        "class ClearMemory(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMHJDCAHY_Hp"
      },
      "outputs": [],
      "source": [
        "def createCallBack(learning_rate):\n",
        "\n",
        "    \n",
        "    callbacks = [ReduceLROnPlateau(#monitor='accuracy',\n",
        "                                   monitor ='val_loss',\n",
        "                                   factor=0.1,\n",
        "                                   patience=5,\n",
        "                                   min_lr=learning_rate / 1000),\n",
        "                 EarlyStopping(#monitor='accuracy',\n",
        "                                monitor ='val_loss',\n",
        "                              patience=9,  \n",
        "                               min_delta=0.0001),\n",
        "                 ClearMemory()]\n",
        "\n",
        "\n",
        "    return callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moLfRa0KzKIj"
      },
      "source": [
        "# Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQoG__tzzICJ"
      },
      "outputs": [],
      "source": [
        "class load_img_sets():\n",
        "  \"\"\"Cross validation is much easier to perform when images are in the form\n",
        "  of numpy arrays and not tf.data.Dataset. This class serves to convert \n",
        "  tf.data.Dataset objects to numpy arrays.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        path : str\n",
        "            The path to the image dataset\n",
        "\n",
        "        batch_size : int\n",
        "            The size of batch that images will be read in and converted to \n",
        "            arrays. (defaults to 64)\n",
        "        \n",
        "        ignore_other : bool\n",
        "            A flag that can be set that will ignore ECGs that are not AF or \n",
        "            NORMAL (defaults to True)\n",
        "    Methods\n",
        "    ------\n",
        "        load_data()\n",
        "            Function used to load in image data and convert it to numpy\n",
        "            arrays\n",
        "\n",
        "        load_af_data()\n",
        "            Function used to load in image data specifically for one sub direc-\n",
        "            tory, in this case AF.\n",
        "       \n",
        "  \"\"\"\n",
        "  def __init__(self,path,batch_size=64,ignore_other = True):\n",
        "\n",
        "    self.path = path\n",
        "    self.batch_size = batch_size\n",
        "    self.ignore = ignore_other\n",
        "\n",
        "  def load_data(self):\n",
        "    \"\"\"Function used to load in image data and convert it to numpy\n",
        "      arrays.\n",
        "\n",
        "    Returns\n",
        "    ------\n",
        "        X : np.ndarray\n",
        "          numpy array of images\n",
        "        Y : np.ndarray\n",
        "          numpy array of lables\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    Y = []\n",
        "    ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    self.path,\n",
        "    image_size=(128, 128),\n",
        "    batch_size=self.batch_size,\n",
        "    color_mode='grayscale'\n",
        "    )\n",
        "    for image_batch,label_batch in ds:\n",
        "        for image,label in zip(image_batch,label_batch):\n",
        "            if self.ignore:\n",
        "              if label.numpy()!=2:\n",
        "                X.append(tf.keras.preprocessing.image.img_to_array(image))\n",
        "                # without this part, 0 => AF implying AF is the negative class\n",
        "                if label == 0: #convert af label to 1\n",
        "                  Y.append(label.numpy()+1)\n",
        "                if label == 1: #convert normal label to 0\n",
        "                  Y.append(label.numpy()-1)\n",
        "            else:\n",
        "              X.append(tf.keras.preprocessing.image.img_to_array(image))\n",
        "              Y.append(label.numpy())\n",
        "    return np.asarray(X),np.asarray(Y)\n",
        "\n",
        "  def load_af_data(self):\n",
        "    \"\"\"Function used to load in image data specifically for one sub direc-\n",
        "      tory, in this case AF.\n",
        "\n",
        "    Returns\n",
        "    ------\n",
        "        X : np.ndarray\n",
        "          numpy array of images\n",
        "        Y : np.ndarray\n",
        "          numpy array of lables\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    Y = []\n",
        "    ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    self.path,\n",
        "    label_mode = None,\n",
        "    image_size=(128, 128),\n",
        "    batch_size=self.batch_size,\n",
        "    color_mode='grayscale'\n",
        "    )\n",
        "    for image_batch in ds:\n",
        "        for image in image_batch:\n",
        "              X.append(tf.keras.preprocessing.image.img_to_array(image))\n",
        "              Y.append(1) #0 corresponds to af simply due to the nature of this function\n",
        "    return np.asarray(X),np.asarray(Y)\n",
        "          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXCoa6CoqWSg"
      },
      "source": [
        "# Cross Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generate ECGs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOV6wBmBOs3Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "def label_maker(n_classes=2,ecg_type='NORMAL', num_eg=16):\n",
        "    \"\"\"A helper function used to generate a set of labels (NORMAL,AF,OTHER)\n",
        "      to be used in image generation functions. Generates a tensor of zero, one, or \n",
        "      two equalling length of the num_eg parameter.\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      n_classes : int\n",
        "          not necessary\n",
        "\n",
        "      ecg_type : str\n",
        "          A string indicating the type of ECG to generate. Accepted arguments\n",
        "          are 'NORMAL', 'AF', or 'OTHER'.\n",
        "      \n",
        "      num_eg : int\n",
        "          The number of labels to generate\n",
        "\n",
        "      Returns\n",
        "      ------\n",
        "      labels\n",
        "          A tensor of labels of either 0,1 or 2 corresponding to AF, NORMAL or\n",
        "          OTHER\n",
        "      \"\"\"\n",
        "    if ecg_type == 'AF':\n",
        "        lab = tf.cast(0,  dtype=tf.dtypes.int32) # generators were trained with AF = 0 but that will \n",
        "        # not work with other keras metrics so we keep AF = 0 here but \n",
        "        # when we read in the data to np arrays we swap the values from AF = 0 to AF = 1\n",
        "    elif ecg_type == 'NORMAL':\n",
        "        lab = tf.cast(1,  dtype=tf.dtypes.int32)\n",
        "    else:\n",
        "        lab = tf.cast(2,  dtype=tf.dtypes.int32)\n",
        "    return tf.repeat(lab, [num_eg], axis=None, name=None)\n",
        "\n",
        "def generate_new_images_is(model, num_eg,ecg_type = 'NORMAL', batch_size=1000):\n",
        "    \"\"\"A function used to generate a set of images as numpy arrays\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        model : tf.Model\n",
        "            The generator to be used to generate images.\n",
        "\n",
        "        epoch : int\n",
        "            The current epoch of training\n",
        "        \n",
        "        seed : tf.Tensor\n",
        "            A fixed tensor of shape num_eg*latent_dim containing random numbers\n",
        "            drawn from the Gaussian distribution where num_eg is the required\n",
        "            number of fake ECGs to generate.\n",
        "          \n",
        "        ecg_type : str\n",
        "            A string indicating the type of ECG to generate. Accepted arguments\n",
        "            are 'NORMAL', 'AF', or 'OTHER'. Used in conjunction with the label_gen\n",
        "            function to generate a tenesor of integers corresponding to the\n",
        "            chosen ECG type.\n",
        "        batch_size : int\n",
        "            Number of ECGs generated in a given iteration. Must equally divide\n",
        "            num_eg (defaults to 1000)\n",
        "    \"\"\"\n",
        "    limit = num_eg//batch_size\n",
        "    count = 0\n",
        "    if num_eg%batch_size!=0:\n",
        "      print(\"please ensure batch size and number of examples are divisible\")\n",
        "      return\n",
        "    imgs = []\n",
        "    for i in range(limit):\n",
        "      input = tf.random.normal([batch_size, 100])\n",
        "      labels = label_maker(n_classes=2, ecg_type = ecg_type, num_eg = batch_size)\n",
        "\n",
        "      predictions = model([input, labels], training=False)\n",
        "      \n",
        "      for j in range(predictions.shape[0]):\n",
        "          pred = (predictions[j, :, :, :] + 1 ) * 127.5\n",
        "          pred = np.asarray(pred)  \n",
        "          imgs.append(pred)\n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R77nYa0QBzLA"
      },
      "source": [
        "#### Normalize images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fTN1ZBWMx2d"
      },
      "outputs": [],
      "source": [
        "def normalize(train, test,fake=None):\n",
        "  \"\"\"A function used to preprocess image data.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "      train : np.ndarray\n",
        "          Training image set\n",
        "\n",
        "      test : np.ndarray\n",
        "          Testing image set\n",
        "      fake : np.ndarray\n",
        "          Optional fake image set that will later be \n",
        "          combined with the training set. (defaults to None)\n",
        "  Returns\n",
        "  ------\n",
        "      train_norm : np.ndarray\n",
        "          normalized training set\n",
        "      \n",
        "      test_norm : np.ndarray\n",
        "          normalized test set\n",
        "      \n",
        "      fake_norm : (optional) np.ndarry\n",
        "          normalized fake set\n",
        "  \"\"\"\n",
        "\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "\n",
        "  if fake is not None:\n",
        "    fake_norm = fake.astype('float32')\n",
        "    fake_norm = fake_norm / 255.0\n",
        "    return train_norm, test_norm,fake_norm\n",
        "\n",
        "  return train_norm, test_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwCVXrDW-kjr"
      },
      "outputs": [],
      "source": [
        "# X_train,X_valid,X_test=prep_pixels(X_train,X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5iNK3PAk_hO"
      },
      "outputs": [],
      "source": [
        "# X_train,X_test,X_fake=normalize(X_train,X_test,X_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOQjdt3zKs1r"
      },
      "outputs": [],
      "source": [
        "# print(X_train.shape,X_test.shape,X_fake.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9whOQ9pB4jA"
      },
      "source": [
        "#### Save Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVWhsSE2leDP"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcunGFh6QWDG"
      },
      "outputs": [],
      "source": [
        "def save_for_cross_val(train,t_lab,valid,v_lab,dir,k=5,shuf = False):\n",
        "  \"\"\"A splitting function used to manually split up datasets into \n",
        "  folds for cross valudation.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "      train : np.ndarry\n",
        "        Training image set\n",
        "      t_lab : np.ndarry\n",
        "        Training label set\n",
        "      valid : np.ndarry\n",
        "        Other image set\n",
        "      v_lab : np.ndarry\n",
        "        Other label set\n",
        "      dir : str\n",
        "        Directory to save folds to\n",
        "      k : int\n",
        "        Number of folds to split data into (Defaults to 5)\n",
        "      shuf : bool\n",
        "        Flag controlling wether or not the dataset should be shuffled\n",
        "        before folding (defaults to False). If using augmentation, this\n",
        "        MUST be True\n",
        "\n",
        "  \"\"\"\n",
        "  datasets = np.concatenate((train,valid))\n",
        "  \n",
        "  labels = np.concatenate((t_lab,v_lab))\n",
        "  print(np.unique(labels,return_counts=True))\n",
        "  \n",
        "  if shuf:\n",
        "      print(shuf)\n",
        "      datasets,labels = shuffle(datasets,labels, random_state=0)\n",
        "  datasets = np.array_split(datasets,k,axis=0)\n",
        "  labels = np.array_split(labels,k,axis=0)\n",
        "  fold = 1\n",
        "  for img,label in zip(datasets,labels):\n",
        "    print(fold,img.shape,label.shape)\n",
        "    np.savez(dir+f'/train_{fold}.npz',img,label)\n",
        "    fold+=1\n",
        "\n",
        "  np.savez('/content/train_5.npz',datasets[-1],labels[-1]) # this is done this way\n",
        "  # because in practice, this stops Colab from restarting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Actuall CV code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvleijoK_ffQ"
      },
      "outputs": [],
      "source": [
        "#([training sets], validation set)\n",
        "folds = [([1,2,3,4],5),\n",
        "([1,2,3,5],4),\n",
        "([1,2,4,5],3),\n",
        "([1,3,4,5],2),\n",
        "([2,3,4,5],1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxfjtEyKHlQP"
      },
      "outputs": [],
      "source": [
        "metrics = [keras.metrics.TruePositives(name='tp'),\n",
        "           keras.metrics.FalsePositives(name='fp'),\n",
        "           keras.metrics.TrueNegatives(name='tn'),\n",
        "           keras.metrics.FalseNegatives(name='fn'),\n",
        "           keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "           keras.metrics.Precision(name='precision'),\n",
        "           keras.metrics.Recall(name='recall'),\n",
        "           keras.metrics.AUC(name='auc')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxMc3O_q2C9f"
      },
      "outputs": [],
      "source": [
        "def cross_fold(folds,training_path, holdout_path,learning_rate,batch_size,epochs):\n",
        "    \"\"\"A function used to run cross validation\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        folds : (list,int)\n",
        "            A list of integers to train on and one to test o\n",
        "        training_path : str\n",
        "            Path to training (and validation) folds super-directory\n",
        "        holdout_path : str\n",
        "            Direct path to holdout fold\n",
        "        learning_rate : float\n",
        "            Learning rate of the optimizer\n",
        "        batch_size : int\n",
        "            Number of samples to read into the GPU per time step\n",
        "        epochs : int\n",
        "            Total number of training iterations\n",
        "\n",
        "       \n",
        "    \"\"\"\n",
        "    for i in folds:\n",
        "        K.clear_session()\n",
        "        model = conv_jun()\n",
        "\n",
        "        model.compile(optimizer=keras.optimizers.Adam(\n",
        "                  learning_rate = learning_rate, beta_1 = 0.5, beta_2 = 0.999, amsgrad = False),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=[metrics])\n",
        "        \n",
        "        training_sets = i[0]\n",
        "        evaluating_set = i[1]\n",
        "\n",
        "        for j in training_sets:\n",
        "            print(f'---Training with subset {j}---')\n",
        "\n",
        "            with np.load(training_path+f'/train_{j}.npz') as data:\n",
        "              X = data['arr_0']\n",
        "              Y = data['arr_1']\n",
        "\n",
        "            train_dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
        "            del X\n",
        "            del Y\n",
        "            gc.collect()\n",
        "\n",
        "            #https://github.com/keras-team/keras/issues/4446#issuecomment-261804574\n",
        "\n",
        "            #https://github.com/keras-team/keras/issues/454#issuecomment-125644222\n",
        "      \n",
        "            train_dataset = train_dataset.batch(batch_size)\n",
        "            history = model.fit(train_dataset,\n",
        "                    epochs=epochs,\n",
        "                    verbose=2)\n",
        "          \n",
        "        print(f'---Testing with subset {i[1]}---')\n",
        "        with np.load(training_path+f'/train_{i[1]}.npz') as data:\n",
        "            X = data['arr_0']\n",
        "            Y = data['arr_1']\n",
        "        \n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
        "        del X\n",
        "        del Y\n",
        "        gc.collect()\n",
        "        train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "\n",
        "        model.evaluate(train_dataset,callbacks=tf.keras.callbacks.CSVLogger('eval.log', separator=\";\", append=True))\n",
        "        \n",
        "        print(f'---Testing on holdout---')\n",
        "        with np.load(holdout_path) as data:\n",
        "            X = data['arr_0']\n",
        "            Y = data['arr_1']\n",
        "            X,Y=shuffle(X,Y)\n",
        "            print(np.unique(Y,return_counts=True))\n",
        "\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
        "        del X\n",
        "        del Y\n",
        "        gc.collect()\n",
        "        train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "        model.evaluate(train_dataset,callbacks=tf.keras.callbacks.CSVLogger('eval.log', separator=\";\", append=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIUPOu7D1sfj"
      },
      "source": [
        "# **Use Cases**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7V77ER18INN"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI_gQ23DBXIN"
      },
      "source": [
        "Get Control set and ***UNSEEN HOLDOUT***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmGnwdDCBWDe"
      },
      "outputs": [],
      "source": [
        "!unzip pre_saved_assests/splits_for_classifier.zip "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM8BNKWo9qvi"
      },
      "source": [
        "#### Select the Assets you wish to use for augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWHBB_VZ1xmq"
      },
      "source": [
        "### Assets for DCCGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7evs-KjQoDnx"
      },
      "outputs": [],
      "source": [
        "!unzip pre_saved_assests/splits_dcgan.zip \n",
        "!unzip pre_saved_assests/dcgan_images.zip \n",
        "!unzip pre_saved_assests/dcgan_gen.zip \n",
        "GEN_PATH = 'content/dcgan_gen'\n",
        "FOLD_PATH = 'content/dcgan_aug'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GwkFbKq1zn0"
      },
      "source": [
        "### Assets for WCGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYPm3Ukr2Y7V"
      },
      "outputs": [],
      "source": [
        "!unzip pre_saved_assests/splits_wgan.zip \n",
        "!unzip pre_saved_assests/wgan_images.zip \n",
        "!unzip pre_saved_assests/wgan_gen_rms.zip \n",
        "GEN_PATH = 'content/wgan_gen_rms'\n",
        "FOLD_PATH = 'content/wgan_aug'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toJckR_y16px"
      },
      "source": [
        "### Assets for WCGANGP RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm79eUFy2VhE"
      },
      "outputs": [],
      "source": [
        "!unzip pre_saved_assests/splits_for_wgangp.zip \n",
        "!unzip pre_saved_assests/wgangp_rms_images.zip \n",
        "!unzip pre_saved_assests/wgangp_gen_rms.zip \n",
        "GEN_PATH = 'content/wgangp_gen_rms'\n",
        "FOLD_PATH = 'content/wgangp_aug'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bru5RQM12WC"
      },
      "source": [
        "### Asssets for WCGANGP Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Psxz1hP1yBg"
      },
      "outputs": [],
      "source": [
        "!unzip pre_saved_assests/splits_for_wgangp_2.zip\n",
        "!unzip pre_saved_assests/wgangp_adam_images.zip #or mbd\n",
        "!unzip pre_saved_assests/wgangp_gen_adam.zip\n",
        "GEN_PATH = 'content/wgangp_adam'\n",
        "FOLD_PATH = 'content/wgangp_aug_adam'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OMFRHyM-XFy"
      },
      "source": [
        "### Select how you want to run cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr8ijwoQ6mgJ"
      },
      "source": [
        "### Running cross validation from presaved folds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is a tendency for checkpoint files to end up in image directories which messes with Keras's ability to read from directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5eKVtgM_-Ry"
      },
      "outputs": [],
      "source": [
        "rm -rf `find ~/Desktop/rsnjos005-AFib_GAN -type d -name .ipynb_checkpoints` #make sure this path is correct for you"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "SLOgkN0S74-j",
        "outputId": "c380b213-c3d3-441e-a9f1-fdd19d41f92b"
      },
      "outputs": [],
      "source": [
        "cross_fold(folds,FOLD_PATH,'content/content/splits_for_classifier/test.npzz',0.001,64,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1Utaa-g82vT"
      },
      "source": [
        "### Producing folds from presaved generator and data splits and running cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nj-mUMF97Tc"
      },
      "outputs": [],
      "source": [
        "!unzip pre_saved_assests/train_final.zip\n",
        "!unzip pre_saved_assests/valid_final.zip\n",
        "!unzip pre_saved_assests/test_final.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-km6aZX5AB6F"
      },
      "outputs": [],
      "source": [
        "rm -rf `find ~/Desktop/rsnjos005-AFib_GAN -type d -name .ipynb_checkpoints` #make sure this path is correct for you"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7XufFu_8-pR",
        "outputId": "3bb845dd-cffc-422a-ff61-0b3a56756a1e"
      },
      "outputs": [],
      "source": [
        "train_ds = load_img_sets('content/images_train',64)\n",
        "X_train,Y_train = train_ds.load_data()\n",
        "\n",
        "valid_ds = load_img_sets('content/images_valid',64)\n",
        "X_valid,Y_valid= valid_ds.load_data()\n",
        "\n",
        "test_ds = load_img_sets('content/images_test',64)\n",
        "X_test,Y_test = test_ds.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJqYgco792SY"
      },
      "outputs": [],
      "source": [
        "X_train = np.concatenate((X_train,X_valid))\n",
        "Y_train = np.concatenate((Y_train,Y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXVMGTDFAQx8",
        "outputId": "91391af1-9080-443b-a3ac-136daa0778d8"
      },
      "outputs": [],
      "source": [
        "generator = keras.models.load_model(GEN_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd-qUYcgAJYq"
      },
      "outputs": [],
      "source": [
        "X_fake = np.asarray(generate_new_images_is(generator,53900,'AF',100))\n",
        "Y_fake = np.ones([X_fake.shape[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aw1TuDP9-u_"
      },
      "outputs": [],
      "source": [
        "X_train,X_test,X_fake=normalize(X_train,X_test,X_fake)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZBPmLPP-Ar8"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "from os import path\n",
        "if path.exists('splits') == False:\n",
        "  os.mkdir('splits')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rSa0ZWJ-CPc",
        "outputId": "c79acbeb-d34a-4cf1-d48d-193315cfb753"
      },
      "outputs": [],
      "source": [
        "save_for_cross_val(X_train,Y_train,X_fake,Y_fake,'splits',shuf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CEsp34t-EUx",
        "outputId": "93eeab9e-082f-4995-a23c-164dd1b35bd1"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5Go-S7T-uMI"
      },
      "outputs": [],
      "source": [
        "FOLD_PATH = 'splits'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "5_nC7ZTn-H-a",
        "outputId": "a13b05c3-d341-485e-bdb0-f0fc44bdcf75"
      },
      "outputs": [],
      "source": [
        "cross_fold(folds,FOLD_PATH,'content/content/splits_for_classifier/test.npz',0.001,64,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk_NwiuKRFx4"
      },
      "source": [
        "## Image quality\n",
        "This section must be run separatley as the PIL version required for clean-fid will force Colab to restart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsrMM_qs_rjW"
      },
      "outputs": [],
      "source": [
        "!pip install clean-fid # You will likely have to restart Colab as this requires an older version of PIL\n",
        "# If that is the case you will need to rerun the prerequisites block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LE5Ao78Y7phm"
      },
      "outputs": [],
      "source": [
        "from cleanfid import fid #this likely will not work without a GPU enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwFOQBOV_LGQ"
      },
      "outputs": [],
      "source": [
        "def get_fid(real_dir,fake_dir):\n",
        "    \"\"\"Uses clean-fid to calculate the Frechét Inception Distance between a set \n",
        "    of real and fake images\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        real_dir : str\n",
        "            directory of real images\n",
        "        fake_dir : str\n",
        "            directory of fake images\n",
        "    Returns\n",
        "    ------\n",
        "        score : float\n",
        "            the FID between images of the two directories\n",
        "    \"\"\"\n",
        "    score = fid.compute_fid(real_dir, fake_dir,mode=\"legacy_tensorflow\")\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij33X9cM_Vi_"
      },
      "outputs": [],
      "source": [
        "def get_kid(real_dir,fake_dir):\n",
        "    \"\"\"Uses clean-fid to calculate the Kernel Inception Distance between a set \n",
        "    of real and fake images\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        real_dir : str\n",
        "            directory of real images\n",
        "        fake_dir : str\n",
        "            directory of fake images\n",
        "    Returns\n",
        "    ------\n",
        "        score : float\n",
        "            the KID between images of the two directories\n",
        "    \"\"\"\n",
        "    score = fid.compute_kid(real_dir, fake_dir,mode=\"legacy_tensorflow\")\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTauD7xLj5Ob"
      },
      "source": [
        "Coputing KID using elementary methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyutLj1SbLSh"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwmWpIafZd3-"
      },
      "outputs": [],
      "source": [
        "device=torch.device(\"cuda\")\n",
        "feat_model = fid.build_feature_extractor('legacy_tensorflow', device) # build Inception\n",
        "x = fid.get_folder_features('/content/images_train', model=feat_model, num_workers=12, num=None,\n",
        "                        shuffle=False, seed=0, batch_size=128, device=torch.device(\"cuda\"),\n",
        "                        mode=\"legacy_tensorflow\", custom_fn_resize=None, description=\"\", verbose=True,\n",
        "                        custom_image_tranform=None) #get real activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjJI-BU6bmTJ"
      },
      "outputs": [],
      "source": [
        "y = fid.get_folder_features('/content/content/adam', model=feat_model, num_workers=12, num=None,\n",
        "                        shuffle=False, seed=0, batch_size=128, device=torch.device(\"cuda\"),\n",
        "                        mode=\"legacy_tensorflow\", custom_fn_resize=None, description=\"\", verbose=True,\n",
        "                        custom_image_tranform=None) #get fake activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtdm3gSi-zw5"
      },
      "source": [
        "### FID and KID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that if these are not run with CUDA enabled they will fail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppUn3jMX-20d"
      },
      "outputs": [],
      "source": [
        "score = get_fid('/content/content/images_train', '/content/content/new_images')\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqj-zONS-576"
      },
      "outputs": [],
      "source": [
        "score = get_kid('/content/content/images_train', '/content/content/new_images')\n",
        "print(score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "V3i2Gtml1TV-",
        "nWHBB_VZ1xmq",
        "8GwkFbKq1zn0",
        "toJckR_y16px",
        "4Bru5RQM12WC",
        "JAJ18vGr537U",
        "anbSmotr6Xd_",
        "nCvAygS6cai5",
        "moLfRa0KzKIj",
        "OXCoa6CoqWSg",
        "vqvXWaQK_9uG",
        "MDBEwWe7AC55",
        "K5RQh8KnYWqs",
        "R77nYa0QBzLA",
        "q9whOQ9pB4jA",
        "NhJOAZ9ZDXpY",
        "gk_NwiuKRFx4",
        "iPmTxct5NaH_",
        "5-tNJGByVOUl"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "cc414e0b3354e9e15d1dfba118355067b70b63730e80deb65fb9da2ad81d92c8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
